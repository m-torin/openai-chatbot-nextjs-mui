import axios, {AxiosResponse} from 'axios';
import {NextApiRequest, NextApiResponse} from 'next';

/**
 * A type that represents the possible roles of a chat message.
 */
export type MessageRole = 'system' | 'user' | 'assistant';

/**
 * An interface that represents a single chat message.
 * @typedef {Object} ChatMessage
 * @property {MessageRole} role - The role of the chat message.
 * @property {string} content - The content of the chat message.
 * @property {MessageRole} readonly role - The role of the chat message (read-only).
 * @property {string} readonly content - The content of the chat message (read-only).
 */
export interface ChatMessage {
  readonly role: MessageRole;
  readonly content: string;
}

/**
 * An interface that represents a request body for the OpenAI chat API.
 * @property {string} model - The ID of the model to use for the chat.
 * @property {ChatMessage[]} messages - An array of chat messages to send.
 */
export interface ChatRequestBody {
  model: string;
  messages: ChatMessage[];
}
/**
 * An interface that represents a response from the OpenAI chat API.
 * @property {string} id - A unique identifier for the chat session.
 * @property {string} object - A string indicating the type of object returned.
 * @property {number} created - A timestamp indicating when the chat session was created.
 * @property {string} model - The ID of the model used for the chat.
 * @property {Object} usage - An object containing information about the usage of the chat API.
 * @property {number} usage.prompt_tokens - The number of tokens used in the prompt.
 * @property {number} usage.completion_tokens - The number of tokens used in the completion.
 * @property {number} usage.total_tokens - The total number of tokens used.
 * @property {Object[]} choices - An array of objects representing the choices made by the model.
 * @property {ChatMessage} choices[].message - The chat message generated by the model.
 * @property {'stop' | 'length'} choices[].finish_reason - A string indicating why the model stopped generating messages.
 * @property {number} choices[].index - The index of the choice in the list of generated messages.
 */
export interface OpenAIChatCompletion {
  readonly id: string;
  readonly object: 'chat.completion';
  readonly created: number;
  readonly model: string;
  readonly usage: {
    readonly prompt_tokens: number;
    readonly completion_tokens: number;
    readonly total_tokens: number;
  };
  readonly choices: ReadonlyArray<{
    readonly message: {
      readonly role: MessageRole;
      readonly content: string;
    };
    readonly finish_reason: 'stop' | 'length';
    readonly index: number;
  }>;
}



/**
 * A union type that represents possible error responses from the server.
 * @typedef {Object} ErrorResponse
 * @property {string} error - A string describing the error that occurred.
 * @property {string} [error='No response received from server'] - A string describing an error that occurs when no response is received from the server.
 * @property {string} [error='Something went wrong'] - A string describing a generic error that occurred.
 */
type ErrorResponse =
  | {error: 'No response received from server'}
  | {error: 'Something went wrong'}
  | {error: string};



/**
 * A function that handles requests to the OpenAI chat API.
 *
 * @async
 * @function handler
 * @param {NextApiRequest} req - The request object.
 * @param {NextApiResponse<OpenAIChatCompletion | ErrorResponse>} res - The response object.
 * @returns {Promise<void>} - A Promise that resolves when the response is sent.
 */
const handler = async (req: NextApiRequest, res: NextApiResponse<OpenAIChatCompletion | ErrorResponse>): Promise<void> => {
  // Set the request headers
  const headers: Record<string, string> = {
    Authorization: `Bearer ${process.env.OPENAI_API_KEY}`,
    'Content-Type': 'application/json',
  };

  // Extract the chat messages from the request body
  const {messages} = req.body;

  // Construct the request body
  const requestBody: ChatRequestBody | undefined = messages && {
    model: 'gpt-4' ?? 'gpt-3.5-turbo',
    messages,
  };
  
  try {
    // Send the chat API request and receive the response
    const response: AxiosResponse = await axios.post<ChatRequestBody, AxiosResponse>(
      'https://api.openai.com/v1/chat/completions',
      requestBody,
      {headers}
    );

    // Extract the chat completion response from the API response
    const openaiResponse: OpenAIChatCompletion = response.data;

    // Send the chat completion response
    res.status(200).json(openaiResponse);
  } catch (error: any) {
    // Log the error
    console.error(error);

    // Check if the error is an Axios error
    if (axios.isAxiosError(error)) {
      // Handle Axios errors with a response
      if (error.response) {
        res.status(error.response.status).json({error: error.response.statusText});
      } else if (error.request) {
        // Handle Axios errors without a response
        res.status(500).json({error: 'No response received from server'});
      } else {
        // Handle other Axios errors
        res.status(500).json({error: 'Something went wrong'});
      }
    } else {
      // Handle other errors
      res.status(500).json({error: 'Something went wrong'});
    }
  }
};


export default handler;
